{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of urllib to import nhd files into memory and push into ScienceBase.  This method first creates a SB item, then attemps to attach files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n",
      "NEW ITEM: {'provenance': {'annotation': 'Python ScienceBase REST test script'}, 'parentId': u'53ece718e4b02bf5a7681838', 'title': 'NHDPlusV1 SourisRedRainy Files Test'}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Other HTTP error: 400: {\"errors\":[{\"message\":\"Property [nativeCrs] of class [class gov.sciencebase.catalog.item.facet.ShapefileFacet] cannot be null\",\"objectName\":\"class gov.sciencebase.catalog.item.Item\",\"field\":\"facets[0].nativeCrs\"},{\"message\":\"Property [nativeCrs] of class [class gov.sciencebase.catalog.item.facet.ShapefileFacet] cannot be null\",\"objectName\":\"class gov.sciencebase.catalog.item.Item\",\"field\":\"facets[0].nativeCrs\"}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8834809aa525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mftpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mnew_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_file_to_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mftpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dwieferich\\Documents\\Python Scripts\\pysb\\SbSession.pyc\u001b[0m in \u001b[0;36mupload_file_to_item\u001b[0;34m(self, item, filename)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupload_file_to_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_files_and_update_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dwieferich\\Documents\\Python Scripts\\pysb\\SbSession.pyc\u001b[0m in \u001b[0;36mupload_files_and_update_item\u001b[0;34m(self, item, filenames)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupload_files_and_update_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_files_and_upsert_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dwieferich\\Documents\\Python Scripts\\pysb\\SbSession.pyc\u001b[0m in \u001b[0;36mupload_files_and_upsert_item\u001b[0;34m(self, item, filenames)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dwieferich\\Documents\\Python Scripts\\pysb\\SbSession.pyc\u001b[0m in \u001b[0;36m_get_json\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dwieferich\\Documents\\Python Scripts\\pysb\\SbSession.pyc\u001b[0m in \u001b[0;36m_check_errors\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unauthorized access\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Other HTTP error: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Other HTTP error: 400: {\"errors\":[{\"message\":\"Property [nativeCrs] of class [class gov.sciencebase.catalog.item.facet.ShapefileFacet] cannot be null\",\"objectName\":\"class gov.sciencebase.catalog.item.Item\",\"field\":\"facets[0].nativeCrs\"},{\"message\":\"Property [nativeCrs] of class [class gov.sciencebase.catalog.item.facet.ShapefileFacet] cannot be null\",\"objectName\":\"class gov.sciencebase.catalog.item.Item\",\"field\":\"facets[0].nativeCrs\"}]}"
     ]
    }
   ],
   "source": [
    "#Fails at Shapefile (The shapefile components may need to be all uploaded at once?)\n",
    "\n",
    "import urllib\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "import pysb\n",
    "import getpass\n",
    "import time\n",
    "\n",
    "#Defines directories and credent\n",
    "execfile('theStuff.py')\n",
    "\n",
    "#SB Login\n",
    "sb = pysb.SbSession()\n",
    "sb.loginc(str(loginu))\n",
    "time.sleep(2)   #suggestion from SB, to allow time for login\n",
    "\n",
    "#Create SB item \n",
    "new_item = {'title': 'NHDPlusV1 SourisRedRainy Files Test',\n",
    "    'parentId': sb.get_my_items_id(),\n",
    "    'provenance': {'annotation': 'Python ScienceBase REST test script'}}\n",
    "#new_item = sb.create_item(new_item)\n",
    "print(\"NEW ITEM: \" + str(new_item))\n",
    "\n",
    "#Loop through files from NHDPlusV1 ftp, first read to memory, then upload file to SB item\n",
    "flist = ['NHDPlus09/NHDFlowlineVAA.dbf','NHDPlus09/Hydrography/NHDFlowline.dbf','NHDPlus09/Hydrography/NHDFlowline.prj','NHDPlus09/Hydrography/nhdflowline.shp','NHDPlus09/Hydrography/nhdflowline.shx']    \n",
    "mysock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(mysock.read())\n",
    "with ZipFile(memfile, 'r') as ftpl:\n",
    "    for file in flist:\n",
    "        test = ftpl.extract(file)\n",
    "        new_item = sb.upload_file_to_item(new_item, test)\n",
    "ZipFile.close(ftpl)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of urllib to import nhd files into memory, create a zipfile and push into ScienceBase.  This method first creates a SB item, then creates a zip file, adding the in memory files to the zip file and then attemps to push the zip file to sciencebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "import pysb\n",
    "import getpass\n",
    "import time\n",
    "\n",
    "#Defines directories and credent\n",
    "execfile('theStuff.py')\n",
    "\n",
    "sb = pysb.SbSession()\n",
    "sb.loginc(str(loginu))\n",
    "#suggestion from SB, to allow time for login\n",
    "time.sleep(2)\n",
    "\n",
    "mysock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(mysock.read())\n",
    "with ZipFile(memfile, 'r') as ftpl:\n",
    "        test = ftpl.extract('NHDPlus09/NHDFlowlineVAA.dbf')\n",
    "        test1 = ftpl.extract('NHDPlus09/Hydrography/NHDFlowline.dbf')\n",
    "        test2 = ftpl.extract('NHDPlus09/Hydrography/NHDFlowline.prj')\n",
    "        test3 = ftpl.extract('NHDPlus09/Hydrography/nhdflowline.shp')\n",
    "        test4 = ftpl.extract('NHDPlus09/Hydrography/nhdflowline.shx')\n",
    "ZipFile.close(ftpl) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "NHDFlowline.dbf                                2017-05-23 15:50:22      7109640\n",
      "NHDFlowline.prj                                2017-05-23 15:50:22          167\n",
      "NHDFlowline.shp                                2017-05-23 15:50:22     33005524\n",
      "NHDFlowline.shx                                2017-05-23 15:50:22       264628\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method ZipFile.close of <zipfile.ZipFile object at 0x000000000679C3C8>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing creation of zip file into memory\n",
    "import StringIO\n",
    "zf = ZipFile(StringIO.StringIO(), mode='a')\n",
    "zf.write(test1, 'NHDFlowline.dbf')\n",
    "zf.write(test2, 'NHDFlowline.prj')\n",
    "zf.write(test3, 'NHDFlowline.shp')\n",
    "zf.write(test4, 'NHDFlowline.shx')\n",
    "\n",
    "print zf.printdir()\n",
    "\n",
    "zf.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "coercing to Unicode: need string or buffer, ZipFile found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c3f224ec91d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     'provenance': {'annotation': 'Python ScienceBase REST test script'}}\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_item\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnew_item\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_files_and_update_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mzf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\dwieferich\\Documents\\Python Scripts\\pysb\\SbSession.pyc\u001b[0m in \u001b[0;36mupload_files_and_update_item\u001b[0;34m(self, item, filenames)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupload_files_and_update_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_files_and_upsert_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dwieferich\\Documents\\Python Scripts\\pysb\\SbSession.pyc\u001b[0m in \u001b[0;36mupload_files_and_upsert_item\u001b[0;34m(self, item, filenames)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: coercing to Unicode: need string or buffer, ZipFile found"
     ]
    }
   ],
   "source": [
    "new_item = {'title': 'NHDPlusV1 SourisRedRainy Files Test',\n",
    "    'parentId': sb.get_my_items_id(),\n",
    "    'provenance': {'annotation': 'Python ScienceBase REST test script'}}\n",
    "new_item = sb.create_item(new_item)\n",
    "new_item = sb.upload_files_and_update_item(new_item, [zf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sending zip file to local disk, then pushing up to SB works fine\n",
    "\n",
    "zf = ZipFile(testing.zip, mode='a')\n",
    "zf.write(test1, 'NHDFlowline.dbf')\n",
    "zf.write(test2, 'NHDFlowline.prj')\n",
    "zf.write(test3, 'NHDFlowline.shp')\n",
    "zf.write(test4, 'NHDFlowline.shx')\n",
    "\n",
    "new_item = {'title': 'NHDPlusV1 SourisRedRainy Files Test',\n",
    "    'parentId': sb.get_my_items_id(),\n",
    "    'provenance': {'annotation': 'Python ScienceBase REST test script'}}\n",
    "new_item = sb.create_item(new_item)\n",
    "sb.upload_file_to_item(new_item, zf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial testing as notes are found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "\n",
    "mysock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(mysock.read())\n",
    "with ZipFile(memfile, 'r') as f:\n",
    "    test = f.extract('NHDPlus09/NHDFlowlineVAA.dbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pysb\n",
    "import getpass\n",
    "import time\n",
    "execfile('theStuff.py')\n",
    "\n",
    "sb = pysb.SbSession()\n",
    "sb.loginc(str(loginu))\n",
    "#suggestion from SB, to allow time for login\n",
    "time.sleep(2)\n",
    "\n",
    "new_item = {'title': 'This is a new test item',\n",
    "    'parentId': sb.get_my_items_id(),\n",
    "    'provenance': {'annotation': 'Python ScienceBase REST test script'}}\n",
    "new_item = sb.create_item(new_item)\n",
    "print(\"NEW ITEM: \" + str(new_item))\n",
    "\n",
    "# Upload a file to the newly created item\n",
    "new_item = sb.upload_file_to_item(new_item, test)\n",
    "print(\"FILE UPDATE: \" + str(new_item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "flist = ['NHDPlus09/NHDFlowlineVAA.dbf','NHDPlus09/Hydrography/NHDFlowline.dbf','NHDPlus09/Hydrography/NHDFlowline.prj','NHDPlus09/Hydrography/nhdflowline.shp','NHDPlus09/Hydrography/nhdflowline.shx']    \n",
    "filenum = 1\n",
    "filename = file + str(filenum)\n",
    "with ZipFile(memfile, 'r') as f:\n",
    "    for fl in flist:\n",
    "        filename \n",
    "    vaa = f.extract('NHDPlus09/NHDFlowlineVAA.dbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "\n",
    "mysock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(mysock.read())\n",
    "file = ZipFile(memfile)\n",
    "#with ZipFile(memfile, 'r') as myzip:\n",
    "#    f = myzip.open('NHDPlus09/NHDFlowlineVAA.dbf')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "\n",
    "namelist = []\n",
    "mysock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(mysock.read())\n",
    "ZipFile(memfile, )\n",
    "with ZipFile(memfile, 'r') as f:\n",
    "    f.extract('NHDPlus09/NHDFlowlineVAA.dbf', 'C:/dw/nhdplusv1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "namelist = []\n",
    "mysock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(mysock.read())\n",
    "ZipFile(memfile, )\n",
    "with ZipFile(memfile, 'r') as f:\n",
    "    filename = os.path.basename('NHDPlus09/NHDFlowlineVAA.dbf')\n",
    "    source = f.open(member)\n",
    "    target = file(os.path.join('C:/dw/nhdplusv1', filename), \"wb\")\n",
    "    with source, target:\n",
    "        shutil.copyfileobj(source,target)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "\n",
    "mysock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(mysock.read())\n",
    "with ZipFile(memfile, 'r') as f:\n",
    "    data = f.read('NHDPlus09/NHDFlowlineVAA.dbf')\n",
    "    print len(data), repr(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = file(file, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing of FTP to access NHDPlusV1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib \n",
    "import zipfile\n",
    "import os\n",
    "from ftplib import FTP\n",
    "\n",
    "#Defines directories and credent\n",
    "execfile('theStuff.py')\n",
    "\n",
    "reglist = (\"California\",\"Colorado\",\"GreatBasin\", \"GreatLakes\",\"MidAtlantic\",\"Mississippi\",\"NewEngland\",\"PacificNorthWest\",\"RioGrande\",\"SourisRedRainy\",\"SouthAtlanticGulf\",\"TexasGulf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "\n",
    "class Reader:\n",
    "  def __init__(self):\n",
    "    self.data = \"\"\n",
    "  def __call__(self,s):\n",
    "     self.data += s\n",
    "\n",
    "ftp = FTP('ftp.horizon-systems.com')\n",
    "ftp.login()\n",
    "r = Reader()\n",
    "ftp.retrbinary('RETR NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip' , r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for region in reglist:\n",
    "    ftp = FTP('ftp.horizon-systems.com')\n",
    "    ftp.login()\n",
    "    ftpdir = \"NHDplus/NHDPlusV1/\" + region + \"/\"\n",
    "    ftp.cwd(ftpdir)\n",
    "    #ftp.cwd('NHDplus/NHDPlusV1/SourisRedRainy/')\n",
    "    \n",
    "    filenames = ftp.nlst()\n",
    "    ftp.quit\n",
    "\n",
    "##########################################\n",
    "    wanted = ['*NHD.zip']\n",
    "    matched = []\n",
    "\n",
    "    for w in wanted:\n",
    "        f = fnmatch.filter(filenames, w)\n",
    "        matched += f\n",
    "#########################################\n",
    "\n",
    "    for m in matched:\n",
    "        local_filename = os.path.join(nhdpv1Dir, m)\n",
    "        file = open(local_filename, 'wb')\n",
    "        ftp.retrbinary('RETR '+filename, file.read)\n",
    "        print m + \" is done\"\n",
    "        file.close()\n",
    "    ftp.quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fails at Shapefile (The shapefile components may need to be all uploaded at once?)\n",
    "\n",
    "import urllib\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "import pysb\n",
    "import getpass\n",
    "import time\n",
    "execfile('theStuff.py')\n",
    "\n",
    "RegionDict = {\n",
    "\"California\": \"\"\"{\"nhdV\": \"V01_02\",\"catV\": \"V01_01\"}\"\"\",\n",
    "\"Colorado\":  \"\"\"{\"nhdV\": \"V01_03\",\"catV\": \"V01_01\"}\"\"\",\n",
    "\"GreatBasin\": \"\"\"{\"nhdV\": \"V01_02\",\"catV\": \"V01_01\"}\"\"\",\n",
    "\"GreatLakes\": \"\"\"{\"nhdV\": \"V01_02\",\"catV\": \"V01_01\"}\"\"\",\n",
    "\"MidAtlantic\": \"\"\"{\"nhdV\": \"V01_02\",\"catV\": \"V01_01\"}\"\"\",\n",
    "\"Mississippi\": \"\"\"{\"nhdV\": \"V01_03\",\"catV\": \"V01_01\"}\"\"\",\n",
    "    \"\": \"\"}\n",
    "\n",
    "\n",
    "\n",
    "#SB Login\n",
    "sb = pysb.SbSession()\n",
    "sb.loginc(str(loginu))\n",
    "time.sleep(2)   #suggestion from SB, to allow time for login\n",
    "\n",
    "#Create SB item \n",
    "new_item = {'title': 'NHDPlusV1 SourisRedRainy Files Test',\n",
    "    'parentId': sb.get_my_items_id(),\n",
    "    'provenance': {'annotation': 'Python ScienceBase REST test script'}}\n",
    "#new_item = sb.create_item(new_item)\n",
    "print(\"NEW ITEM: \" + str(new_item))\n",
    "\n",
    "#Loop through files from NHDPlusV1 ftp, first read to memory, then upload file to SB item\n",
    "flist = ['NHDPlus09/NHDFlowlineVAA.dbf','NHDPlus09/Hydrography/NHDFlowline.dbf','NHDPlus09/Hydrography/NHDFlowline.prj','NHDPlus09/Hydrography/nhdflowline.shp','NHDPlus09/Hydrography/nhdflowline.shx']    \n",
    "catsock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip') \n",
    "flowsock = urllib.urlopen('ftp://ftp.horizon-systems.com/NHDplus/NHDPlusV1/SourisRedRainy/NHDPlus09V01_02_NHD.zip')  \n",
    "memfile = io.BytesIO(flowsock.read())\n",
    "with ZipFile(memfile, 'r') as ftpl:\n",
    "    for file in flist:\n",
    "        test = ftpl.extract(file)\n",
    "        new_item = sb.upload_file_to_item(new_item, test)\n",
    "ZipFile.close(ftpl)  \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
