{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, json, io, urllib\n",
    "from zipfile import ZipFile\n",
    "#import zipfile\n",
    "#from contextlib import closing\n",
    "import urllib.request as ur\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from simpledbf import Dbf5\n",
    "from bis2 import gc2\n",
    "import string\n",
    "\n",
    "q='''https://www.sciencebase.gov/catalog/items?filter=tags={%22scheme%22:%22BIS%22,%22name%22:%22NHDPlusV2.1%22}&fields=files,id,tags&format=json'''\n",
    "#Returns \n",
    "nhdItems = requests.get(q).json()\n",
    "\n",
    "# Set up the actions/targets for this particular instance\n",
    "thisRun = {}\n",
    "thisRun[\"instance\"] = \"DataDistillery\"\n",
    "thisRun[\"db\"] = \"BCB\"\n",
    "thisRun[\"baseURL\"] = gc2.sqlAPI(thisRun[\"instance\"],thisRun[\"db\"])\n",
    "thisRun[\"schema\"] = \"sfr\"\n",
    "thisRun[\"commitToDB\"] = False\n",
    "\n",
    "\n",
    "#Query comids already in the table\n",
    "q_recordToSearch = \"SELECT comid as lookup FROM nhd.nhdplusv2_plusflowlinevaa \" \n",
    "recordToSearch = requests.get(thisRun[\"baseURL\"]+\"&q=\"+q_recordToSearch).json()\n",
    "p = recordToSearch['features']\n",
    "lookup = []\n",
    "#for record returned, add record to list\n",
    "for f in p:\n",
    "    lookup.append(f['properties']['lookup'])\n",
    "lenList = len(lookup)\n",
    "cntExisting = 0 \n",
    "existingList = []\n",
    "    \n",
    "\n",
    "\n",
    "for item in nhdItems['items']:\n",
    "    #Identify which NHD Region via tags \n",
    "    for tag in item['tags']:\n",
    "        if 'Reg' in tag['name']:\n",
    "            region = tag['name']\n",
    "    #Look at files and find NHDPlusAttributes File\n",
    "    for file in item['files']:\n",
    "        fileName = file['name']\n",
    "        if 'NHDPlusAttributes' in fileName:\n",
    "            #Download file\n",
    "            print ('Retrieving region ' + region + ', file:' + fileName)\n",
    "            fileUrl = file['url']\n",
    "            ur.urlretrieve(fileUrl, fileName)\n",
    "            #Unzip file.  Ideally this will be transformed to work in memory\n",
    "            subprocess.call(r'\"C:\\Program Files\\7-Zip\\7z.exe\" x ' + fileName)\n",
    "            \n",
    "            #Convert dbf to dataframe\n",
    "            dbf = Dbf5('PlusFlowLineVAA.dbf')\n",
    "            df = dbf.to_dataframe()\n",
    "            for row in df.itertuples():\n",
    "                if row.ComID in lookup:\n",
    "                    continue\n",
    "                else:\n",
    "                    q = \"insert into nhd.nhdplusv2_plusflowlinevaa \\\n",
    "                    (comid, fdate, streamleve, streamorde, streamcalc, fromnode, tonode, hydroseq, levelpath1, \\\n",
    "                    pathlength, terminalpat, arbolatesu, divergence, startflag, terminalfl, dnlevel,  thinnercod, \\\n",
    "                    uplevelpat, uphydroseq, dnlevelpat, dnminorhyd, dndraincou, dnhydroseq, frommeas, tomeas, \\\n",
    "                    reachcode, lengthkm, fcode, rtndiv, outdiv, diveeffect, vpuin, vpuout, areasqkm, totdasqkm, \\\n",
    "                    divdasqkm, tidal, totma, wbareatype) VALUES \\\n",
    "                    ('\" + str(row.ComID) + \"' ,'\" + str(row.Fdate) + \"' ,'\" + str(row.StreamLeve) + \"' ,'\"  \\\n",
    "                    + str(row.StreamOrde) + \"' ,'\" + str(row.StreamCalc) + \"' ,'\" + str(row.FromNode) + \"' ,'\" \\\n",
    "                    + str(row.ToNode) + \"' ,'\" + str(row.Hydroseq) + \"' ,'\" + str(row.LevelPathI) +  \"' ,'\" \\\n",
    "                    + str(row.Pathlength)+ \"' ,'\" + str(row.TerminalPa) + \"' ,'\" + str(row.ArbolateSu) + \"' ,'\" \\\n",
    "                    + str(row.Divergence) + \"' ,'\" + str(row.StartFlag) + \"' ,'\" + str(row.TerminalFl) + \"' ,'\" \\\n",
    "                    + str(row.DnLevel) + \"' ,'\" +   str(row.ThinnerCod) + \"' ,'\" +   str(row.UpLevelPat) + \"' ,'\" \\\n",
    "                    + str(row.UpHydroseq) + \"' ,'\" + str(row.DnLevelPat) + \"' ,'\" + str(row.DnMinorHyd) + \"' ,'\" \\\n",
    "                    + str(row.DnDrainCou) + \"' ,'\" + str(row.DnHydroseq) + \"' ,'\" + str(row.FromMeas) + \"' ,'\" \\\n",
    "                    + str(row.ToMeas) + \"' ,'\" + str(row.ReachCode) + \"' ,'\" + str(row.LengthKM) + \"' ,'\" \\\n",
    "                    + str(row.Fcode) + \"' ,'\" + str(row.RtnDiv) + \"' ,'\" + str(row.OutDiv) + \"' ,'\" \\\n",
    "                    + str(row.DivEffect) + \"' ,'\" + str(row.VPUIn) + \"' ,'\" + str(row.VPUOut) + \"' ,'\" \\\n",
    "                    + str(row.AreaSqKM) + \"' ,'\" + str(row.TotDASqKM) + \"' ,'\" + str(row.DivDASqKM) + \"' ,'\" \\\n",
    "                    + str(row.Tidal) + \"' ,'\" + str(row.TOTMA) + \"' ,'\" + str(row.WBAreaType) + \"')\"\n",
    "                    gc2Key = gc2.gc2Keys[\"datadistillery_bcb\"]\n",
    "                    payload = \"q=%s&key=%s\"%(q,gc2Key)\n",
    "                    url= gc2.baseURLs[\"sqlapi_datadistillery_bcb\"]\n",
    "                    finalUrl = url + '?q=' +q + '&key=' + gc2Key\n",
    "                                \n",
    "                    try:\n",
    "                        #r = requests.post(url,data=payload)\n",
    "                        r = requests.get(finalUrl)\n",
    "                        #r.get(finalUrl).json()\n",
    "                        status = str(r.status_code)\n",
    "                        if r.status_code == 200:\n",
    "                            continue\n",
    "                        else:\n",
    "                            print (str(row.ComID) + ' failed with code: ' + status)\n",
    "                    except requests.exceptions.HTTPError:\n",
    "                        print (str(row.ComID) + ' failed with code: ' + status)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving region Reg14, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg8, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg13, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg2, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg18, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg17, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg7, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg4, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg9, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg1, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg12, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg3, file:NHDPlusAttributes03N.zip\n",
      "Retrieving region Reg3, file:NHDPlusAttributes03S.zip\n",
      "Retrieving region Reg3, file:NHDPlusAttributes03W.zip\n",
      "Retrieving region Reg5, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg15, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg10L, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg16, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg10U, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg6, file:NHDPlusAttributes.zip\n"
     ]
    }
   ],
   "source": [
    "import requests, json, io, urllib\n",
    "from zipfile import ZipFile\n",
    "import zipfile\n",
    "#from contextlib import closing\n",
    "import urllib.request as ur\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from simpledbf import Dbf5\n",
    "from bis2 import gc2\n",
    "import string\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "q='''https://www.sciencebase.gov/catalog/items?filter=tags={%22scheme%22:%22BIS%22,%22name%22:%22NHDPlusV2.1%22}&fields=files,id,tags&format=json'''\n",
    "#Returns \n",
    "nhdItems = requests.get(q).json()\n",
    "\n",
    "# Set up the actions/targets for this particular instance\n",
    "thisRun = {}\n",
    "thisRun[\"instance\"] = \"DataDistillery\"\n",
    "thisRun[\"db\"] = \"BCB\"\n",
    "thisRun[\"baseURL\"] = gc2.sqlAPI(thisRun[\"instance\"],thisRun[\"db\"])\n",
    "thisRun[\"schema\"] = \"sfr\"\n",
    "thisRun[\"commitToDB\"] = False\n",
    "\n",
    "\n",
    "dfAll = None\n",
    "\n",
    "for item in nhdItems['items']:\n",
    "    #Identify which NHD Region via tags \n",
    "    for tag in item['tags']:\n",
    "        if 'Reg' in tag['name']:\n",
    "            region = tag['name']\n",
    "            regFolder = '/' + region\n",
    "            if not os.path.exists(regFolder):\n",
    "                os.makedirs(regFolder)\n",
    "                os.chdir(regFolder)\n",
    "\n",
    "    #Look at files and find NHDPlusAttributes File\n",
    "    for file in item['files']:\n",
    "        fileName = file['name']\n",
    "        if 'NHDPlusAttributes' in fileName:\n",
    "            print ('Retrieving region ' + region + ', file:' + fileName)\n",
    "            fileUrl = file['url']\n",
    "            ur.urlretrieve(fileUrl, fileName)\n",
    "            subprocess.call(r'\"C:\\Program Files\\7-Zip\\7z.exe\" x ' + fileName)\n",
    "                #with zipfile.ZipFile(fileName, \"r\") as zip_ref:\n",
    "                #    zip_ref.extractall(tmpdirname)\n",
    "                #    zip_ref.close()\n",
    "                #Convert dbf to dataframe\n",
    "            dbf = Dbf5('PlusFlowLineVAA.dbf')\n",
    "            df = dbf.to_dataframe()\n",
    "                            \n",
    "            if dfAll is None:\n",
    "                dfAll = df\n",
    "            else:\n",
    "                dfAll.append(df)\n",
    "                    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving region Reg14, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg8, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg13, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg2, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg18, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg17, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg7, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg4, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg9, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg1, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg12, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg3, file:NHDPlusAttributes03N.zip\n",
      "Retrieving region Reg3, file:NHDPlusAttributes03S.zip\n",
      "Retrieving region Reg3, file:NHDPlusAttributes03W.zip\n",
      "Retrieving region Reg5, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg15, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg10L, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg10U, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg16, file:NHDPlusAttributes.zip\n",
      "Retrieving region Reg6, file:NHDPlusAttributes.zip\n"
     ]
    }
   ],
   "source": [
    "import requests, json, io, urllib\n",
    "from zipfile import ZipFile\n",
    "import zipfile\n",
    "#from contextlib import closing\n",
    "import urllib.request as ur\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from simpledbf import Dbf5\n",
    "from bis2 import gc2\n",
    "import string\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "q='''https://www.sciencebase.gov/catalog/items?filter=tags={%22scheme%22:%22BIS%22,%22name%22:%22NHDPlusV2.1%22}&fields=files,id,tags&format=json'''\n",
    "#Returns \n",
    "nhdItems = requests.get(q).json()\n",
    "\n",
    "# Set up the actions/targets for this particular instance\n",
    "thisRun = {}\n",
    "thisRun[\"instance\"] = \"DataDistillery\"\n",
    "thisRun[\"db\"] = \"BCB\"\n",
    "thisRun[\"baseURL\"] = gc2.sqlAPI(thisRun[\"instance\"],thisRun[\"db\"])\n",
    "thisRun[\"schema\"] = \"sfr\"\n",
    "thisRun[\"commitToDB\"] = False\n",
    "\n",
    "\n",
    "dfAll = None\n",
    "\n",
    "for item in nhdItems['items']:\n",
    "    #Identify which NHD Region via tags \n",
    "    for tag in item['tags']:\n",
    "        if 'Reg' in tag['name']:\n",
    "            region = tag['name']\n",
    "            if not os.path.exists('proc'):\n",
    "                os.makedirs('proc')\n",
    "                os.chdir('proc')\n",
    "\n",
    "    #Look at files and find NHDPlusAttributes File\n",
    "    for file in item['files']:\n",
    "        fileName = file['name']\n",
    "        if 'NHDPlusAttributes' in fileName:\n",
    "            print ('Retrieving region ' + region + ', file:' + fileName)\n",
    "            fileUrl = file['url']\n",
    "            ur.urlretrieve(fileUrl, fileName)\n",
    "            subprocess.call(r'\"C:\\Program Files\\7-Zip\\7z.exe\" x ' + fileName)\n",
    "                #with zipfile.ZipFile(fileName, \"r\") as zip_ref:\n",
    "                #    zip_ref.extractall(tmpdirname)\n",
    "                #    zip_ref.close()\n",
    "                #Convert dbf to dataframe\n",
    "            dbf = Dbf5('PlusFlowLineVAA.dbf')\n",
    "            dbf = dbf.to_dataframe()\n",
    "                                       \n",
    "            if dfAll is None:\n",
    "                dfAll = df\n",
    "            else:\n",
    "                dfAll.append(df)\n",
    "            \n",
    "            #df = None\n",
    "            #os.remove('NHDPlusAttributes.zip')\n",
    "            #os.remove('PlusFlow.dbf')\n",
    "            #os.remove('PlusFlowLineVAA.dbf')\n",
    "            #os.remove('elevslope.dbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3343470"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    if 'NHDPlusAttributes' in fileName:\n",
    "            #Download file\n",
    "            print ('Retrieving region ' + region + ', file:' + fileName)\n",
    "            fileUrl = file['url']\n",
    "            ur.urlretrieve(fileUrl, fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                  \n",
    "                    \n",
    "            #zFile = ZipFile(fileName, 'r')\n",
    "            #pd.read_table(zFile.open('PlusFlow.dbf'))\n",
    "                \n",
    "        #if 'Hydrography' in fileName:\n",
    "        #   subprocess.call(r'\"C:\\Program Files\\7-Zip\\7z.exe\" x ' + fileName)\n",
    "        \n",
    "        #Gave error BadZipFile: File is not a zip file\n",
    "        #mysock = urllib.request.urlopen(fileUrl)\n",
    "        #memfile = io.BytesIO(mysock.read())\n",
    "        #ZipFile.infolist(memfile)\n",
    "        #with ZipFile(memfile, 'r') as ftpl:\n",
    "            #ftpl.namelist()\n",
    "            #for file in flist:\n",
    "            #    test = ftpl.extract(file)\n",
    "            #    print (test)\n",
    "      \n",
    "        #Gave error BadZipFile: File is not a zip file\n",
    "        #r = requests.get(fileUrl)\n",
    "        #with closing(r), ZipFile(io.BytesIO(r.content)) as archive:\n",
    "        #    print({member.filename: archive.read(member) for member in archive.infolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (finalurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in nhdFiles['items']:\n",
    "    for tag in item['tags']:\n",
    "        if 'Reg' in tag['name']:\n",
    "            region = tag['name']\n",
    "            print (region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (nhdFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item:\n",
    "    for file in files:\n",
    "        unzip file into memory\n",
    "        if fileName = Flowline*\n",
    "            convert correct file to dataframe\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the actions/targets for this particular instance\n",
    "thisRun = {}\n",
    "thisRun[\"instance\"] = \"DataDistillery\"\n",
    "thisRun[\"db\"] = \"BCB\"\n",
    "thisRun[\"baseURL\"] = gc2.sqlAPI(thisRun[\"instance\"],thisRun[\"db\"])\n",
    "thisRun[\"schema\"] = \"sfr\"\n",
    "thisRun[\"commitToDB\"] = False\n",
    "\n",
    "#Query comids already in the table\n",
    "q_recordToSearch = \"SELECT comid as lookup FROM nhd.nhdplusv2_plusflowlinevaa \" \n",
    "recordToSearch = requests.get(thisRun[\"baseURL\"]+\"&q=\"+q_recordToSearch).json()\n",
    "p = recordToSearch['features']\n",
    "lookup = []\n",
    "#for record returned, add record to list\n",
    "for f in p:\n",
    "    string = f['properties']['lookup']\n",
    "    if string.startswith('\"') and string.endswith('\"'):\n",
    "        string = string[1:-1]  #For some reason these values are coming back with double quotes, this removes outer quote\n",
    "        lookup.append(string)\n",
    "lenList = len(lookup)\n",
    "cntExisting = 0 \n",
    "existingList = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
